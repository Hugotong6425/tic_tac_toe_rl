{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Board():        \n",
    "    # private:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def determine_board_occupation(self, board_status=None):\n",
    "        \"\"\"from the board, determine which player own the cell\n",
    "        \"\"\"\n",
    "        if board_state is None:\n",
    "            board_status = self.state['board'].copy()\n",
    "            \n",
    "        new_board_occupation = np.zeros(9)\n",
    "        \n",
    "        for cell in range(9):\n",
    "            cell_status = board_status[cell]\n",
    "            \n",
    "            if cell_status[2] == 0:\n",
    "                if cell_status[1] == 0:\n",
    "                    if cell_status[0] == 0:\n",
    "                        new_board_occupation[cell] = 0\n",
    "                    elif cell_status[0] == 1:\n",
    "                        new_board_occupation[cell] = 1\n",
    "                    elif cell_status[0] == 2:\n",
    "                        new_board_occupation[cell] = 2\n",
    "                    else:\n",
    "                        print('Error in def update_board_occupation()\\n')\n",
    "                        return False\n",
    "                elif cell_status[1] == 1:\n",
    "                    new_board_occupation[cell] = 1\n",
    "                elif cell_status[1] == 2:\n",
    "                    new_board_occupation[cell] = 2\n",
    "                else:\n",
    "                    print('Error in def update_board_occupation()\\n')\n",
    "                    return False\n",
    "            elif cell_status[2] == 1:\n",
    "                new_board_occupation[cell] = 1\n",
    "            elif cell_status[2] == 2:\n",
    "                new_board_occupation[cell] = 2\n",
    "            else:\n",
    "                print('Error in def update_board_occupation()\\n')\n",
    "                return False\n",
    "            \n",
    "        return new_board_occupation\n",
    "    \n",
    "    def update_board_occupation(self):\n",
    "        \"\"\"update board_occupation\n",
    "        \"\"\"\n",
    "        self.state['board_occupy'] = self.determine_board_occupation()\n",
    "         \n",
    "        return True       \n",
    "    \n",
    "    def is_valid_action(self, action, player):\n",
    "        move_from = action.get('from')\n",
    "        move_to = action.get('to')\n",
    "        move_size = action.get('size')        \n",
    "        board = self.state['board'].copy()\n",
    "        \n",
    "        # if no inventory, then can't move\n",
    "        if move_from == 9 and self.state['%sp_inventory' % player][action.get('size')] == 0:\n",
    "            print('Invalid move! Player %s does not have size %s chess in the inventory!\\n' % (player, move_size))\n",
    "            return False\n",
    "        # if the chess is not on the board, cannot move\n",
    "        elif board[move_from][move_size] != player:\n",
    "            print('Invalid move! On cell %s size %s, the chess does not belong to player %s! \\n' % (move_from, move_size, player))\n",
    "            return False\n",
    "        \n",
    "        # if size smaller than the current block, can't move\n",
    "        target_cell = board[move_to]\n",
    "        is_small_size_occupy_target = (target_cell[0] != 0)\n",
    "        is_medium_size_occupy_target = (target_cell[1] != 0)\n",
    "        is_large_size_occupy_target = (target_cell[2] != 0)\n",
    "        \n",
    "        if move_size == 0 and (is_small_size_occupy_target or is_medium_size_occupy_target or is_large_size_occupy_target):\n",
    "            print('Invalid move! Cannot move to a cell that have same size or larger size chess occupied!\\n')\n",
    "            return False\n",
    "        \n",
    "        elif move_size == 1 and (is_medium_size_occupy_target or is_large_size_occupy_target):\n",
    "            print('Invalid move! Cannot move to a cell that have same size or larger size chess occupied!\\n')\n",
    "            return False\n",
    "        \n",
    "        elif move_size == 2 and (is_large_size_occupy_target):\n",
    "            print('Invalid move! Cannot move to a cell that have same size or larger size chess occupied!\\n')\n",
    "            return False\n",
    "        \n",
    "        # cannot move chess that is under other chess\n",
    "        origin_cell = board[move_from]\n",
    "        is_medium_size_occupy_origin = (target_cell[1] != 0)\n",
    "        is_large_size_occupy_origin = (target_cell[2] != 0)\n",
    "        \n",
    "        if move_size == 0 and (is_medium_size_occupy_origin or is_large_size_occupy_origin):\n",
    "            print('Invalid move! Cannot move to a cell that is under another chess!\\n')\n",
    "            return False\n",
    "        \n",
    "        elif move_size == 1 and (is_large_size_occupy_origin):\n",
    "            print('Invalid move! Cannot move to a cell that is under another chess!\\n')\n",
    "            return False\n",
    "            \n",
    "        # if opponent wins due to this move, then can't move\n",
    "        board[move_from][move_size] = 0\n",
    "        board_occupation = self.determine_board_occupation(board)\n",
    "        is_terminal_state, winner = self.check_if_terminal_state(board_occupation)\n",
    "        if is_terminal_state:\n",
    "            print('Invalid move! Opponent will win due to this move! \\n')\n",
    "            return False\n",
    "             \n",
    "        return True\n",
    "     \n",
    "    def update_state(self, action):\n",
    "        \"\"\"given a valid movement, update the board state\n",
    "        action: {'from': 0, 'to': 0, 'size': 0}\n",
    "        player: 1 or 2\n",
    "        \"\"\"\n",
    "        move_from = action.get('from')\n",
    "        move_to = action.get('to')\n",
    "        move_size = action.get('size')\n",
    "        \n",
    "        player = self.state['player_turn']\n",
    "        \n",
    "        if move_from == 9:\n",
    "            # if from = 9 -> move chess from inventory\n",
    "            self.state['%sp_inventory' % player][action.get('size')] -= 1\n",
    "        else:\n",
    "            # if move from the board, remove the chess on that cell \n",
    "            self.state['board'][move_from][move_size] = 0    \n",
    "            \n",
    "        # put the chess on the new cell\n",
    "        self.state['board'][move_to][move_size] = player\n",
    "        \n",
    "        # update board occupation\n",
    "        self.update_board_occupation()\n",
    "\n",
    "        # change player turn\n",
    "        if self.state['player_turn'] == 1:\n",
    "            self.state['player_turn'] = 2\n",
    "        else:\n",
    "            self.state['player_turn'] = 1\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def determine_reward(self):\n",
    "        is_terminal_state, winner = self.check_if_terminal_state()\n",
    "        if is_terminal_state:\n",
    "            if winner == 1:\n",
    "                return (100, -100)\n",
    "            elif winner == 2:\n",
    "                return (-100, 100)\n",
    "            else:\n",
    "                print(\"Error in determining winner. Current winner is %s.\\n\" % winner)\n",
    "        else:\n",
    "            ### TODO: set reward for occupying cell?\n",
    "            return (0, 0)\n",
    "        \n",
    "    def update_observation_from_state(self):   \n",
    "        # update observation        \n",
    "        self.observation['board'] = self.state['board'].copy()\n",
    "        self.observation['1p_inventory'] = self.state['1p_inventory'].copy()\n",
    "        self.observation['2p_inventory'] = self.state['2p_inventory'].copy()\n",
    "        return True\n",
    "    \n",
    "    def get_activate_player(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    # public:\n",
    "    def reset(self):\n",
    "        self.state = {}\n",
    "        self.state['board'] = np.zeros([9, 3])\n",
    "        self.state['1p_inventory'] = np.array([2, 2, 2])\n",
    "        self.state['2p_inventory'] = np.array([2, 2, 2])\n",
    "        self.state['board_occupy'] = np.zeros(9)\n",
    "        # 1st player moves first\n",
    "        self.state['player_turn'] = 1\n",
    "        \n",
    "        self.observation = {}\n",
    "        self.observation['board'] = np.zeros([9, 3])\n",
    "        self.observation['1p_inventory'] = np.array([2, 2, 2])\n",
    "        self.observation['2p_inventory'] = np.array([2, 2, 2])\n",
    "    \n",
    "    def check_if_terminal_state(self, board_occupation=None):\n",
    "        # if no input board occupation, then get board occupation from self.state['board_occupy']\n",
    "        if board_occupation is None:\n",
    "            board_occupation = self.state['board_occupy']\n",
    "        \n",
    "        for row in range(3):\n",
    "            current_row = board_occupation[row*3:(row+1)*3-1]\n",
    "            \n",
    "            if np.array_equal(current_row, [1, 1, 1]):\n",
    "                return [True, 1]\n",
    "                \n",
    "            if np.array_equal(current_row, [2, 2, 2]):\n",
    "                print('2nd player wins!')\n",
    "                return [True, 2]\n",
    "            \n",
    "        for col in range(3):\n",
    "            current_col = board_occupation[col, col+3, col+6]\n",
    "            \n",
    "            if np.array_equal(current_col, [1, 1, 1]):\n",
    "                return [True, 1]\n",
    "            \n",
    "            if np.array_equal(current_col, [2, 2, 2]):\n",
    "                return [True, 2]\n",
    "            \n",
    "        if (board_occupation[[0, 4, 8]] == [1, 1, 1]) or (board_occupation[[2, 4, 6]] == [1, 1, 1]):\n",
    "            return [True, 1]\n",
    "        \n",
    "        if (board_occupation[[0, 4, 8]] == [2, 2, 2]) or (board_occupation[[2, 4, 6]] == [2, 2, 2]):\n",
    "            return [True, 2]\n",
    "        \n",
    "        # if both win, the mover loss (because it removes the chess and let the other player wins first)\n",
    "        \n",
    "        # if no one wins\n",
    "        return [False, 0]     \n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\" get the activate player from self memory. assume the action is valid, perform the action and \n",
    "        update the state. then swap the active player. return the new observation, reward\n",
    "        \"\"\"\n",
    "        if not is_valid_action(action):\n",
    "            print('Error in def step. Current state is %s. Current action is %s.\\n' % (self.state, action))\n",
    "            return None\n",
    "        \n",
    "        is_terminal_state, winner = self.check_if_terminal_state()\n",
    "        \n",
    "        self.update_state(action, player)\n",
    "        \n",
    "        self.update_observation_from_state()\n",
    "        \n",
    "        reward = self.determine_reward()\n",
    "               \n",
    "        return self.observation, self.state['player_turn'], reward, is_terminal_state\n",
    "    \n",
    "    def get_current_info(self):\n",
    "        return self.observation, self.state['player_turn'], 0, is_terminal_state\n",
    "\n",
    "    \n",
    "    def calculate_reward(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_observation_view(observation, player_id):\n",
    "    '''\n",
    "    player_id either 1 or -1. Swap the observation such that 1 means self and -1 means the opponent \n",
    "    e.g. \n",
    "    if player_id = 1, no need to swap the view,\n",
    "    input = array([[1, -1, 0],\n",
    "                   [0, 0, 0],\n",
    "                   [-1, -1, 1],\n",
    "                   [1, -1, 1],\n",
    "                   [-1, 1, -1]])\n",
    "           \n",
    "    output = array([[-1, 1, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [1, 1, -1],\n",
    "                    [-1, 1, -1],\n",
    "                    [1, -1, 1]])\n",
    "    \n",
    "    '''\n",
    "    swapped_view_observation = observation.copy()\n",
    "    np.putmask(swapped_view_observation, swapped_view_observation == 1, 3)\n",
    "    np.putmask(swapped_view_observation, swapped_view_observation == 2, 1)\n",
    "    np.putmask(swapped_view_observation, swapped_view_observation == 3, 2)\n",
    "    \n",
    "    return swapped_view_observation\n",
    "\n",
    "if False:\n",
    "    observation = np.array([[1,2,0], [0,0,0], [2,2,1], [1,2,1], [2,1,2]])\n",
    "    observation\n",
    "    swap_observation_view(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ab283bd9a1f2>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-ab283bd9a1f2>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    for each record:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def process_memory(memory, is_terminal_state):\n",
    "    if (len(memory) == memory_size + 1) and (is_terminal_state):\n",
    "        # special handle\n",
    "        pass\n",
    "    \n",
    "    # do all the shifting \n",
    "    for each record:\n",
    "        if player is 2:\n",
    "            swap observation, next_observation, reward\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-83b213627a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_terminal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "memory = np.array([])\n",
    "\n",
    "next_observation, player_turn, reward, is_terminal_state = env.step(action)\n",
    "memory.append([original_observation, action, reward, next_observation, player])\n",
    "\n",
    "if (len(memory) == memory_size + 1) or (is_terminal_state):\n",
    "    # shift reward, state, done, and assign 1 for my round and 2 for the opponent round\n",
    "    memory_for_training = process_memory(memory, is_terminal_state)\n",
    "    if is_terminal_state:\n",
    "        memory = np.array([])\n",
    "    else:\n",
    "        memory = memory[-1]\n",
    "        \n",
    "    agent.learn(memory_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main flow\n",
    "\n",
    "load_weight_path = 'dummy_path'\n",
    "model_weight_path = 'dummy_path'\n",
    "\n",
    "env = make_env()\n",
    "bot1 = Bot(load_weight_path)\n",
    "bot2 = Bot()\n",
    "bot_list = [bot1, bot2]\n",
    "unprocess_memory = np.array([])\n",
    "\n",
    "num_episode = 10\n",
    "\n",
    "\n",
    "for episode in range(num_episode):\n",
    "    env.reset()\n",
    "    \n",
    "    # get initial state\n",
    "    observation, player_turn, reward, is_terminal_state = env.get_current_info()\n",
    "    \n",
    "    while not is_terminal_state:\n",
    "        # if now is player 2's turn, swap the observation\n",
    "        if player_turn == 2:\n",
    "            swapped_observation = swap_observation_view(observation)\n",
    "            action = bot_list[player_turn-1].select_action(swapped_observation)\n",
    "        elif player_turn == 1:\n",
    "            action = bot_list[player_turn-1].select_action(observation)\n",
    "        else:\n",
    "            print('Error in player turn. Current player turn is %s.\\n' % player_turn)\n",
    "        \n",
    "        next_observation, next_player_turn, reward, is_terminal_state = env.step(action)\n",
    "        \n",
    "        unprocess_memory.append([observation, action, reward, next_observation, player_turn])\n",
    "        \n",
    "        if (len(unprocess_memory) == memory_size + 1) or (is_terminal_state):\n",
    "            # shift reward, state, done, and assign 1 for my round and 2 for the opponent round\n",
    "            memory_for_training = process_memory(unprocess_memory, is_terminal_state)\n",
    "            if is_terminal_state:\n",
    "                unprocess_memory = np.array([])\n",
    "            else:\n",
    "                unprocess_memory = unprocess_memory[-1]\n",
    "\n",
    "            bot1.learn(memory_for_training)\n",
    "            \n",
    "        observation, player_turn = next_observation, next_player_turn\n",
    "        \n",
    "    # save the model weight periodically\n",
    "    if (episode + 1) % 50 == 0:\n",
    "        bot1.save_weight(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot():\n",
    "    def __init__(self, load_weight_path=None):\n",
    "        self.observation['board'] = np.zeros([9, 3])\n",
    "        self.observation['1p_inventory'] = np.array([2, 2, 2])\n",
    "        self.observation['2p_inventory'] = np.array([2, 2, 2])\n",
    "                \n",
    "        self.model = self.build_model()\n",
    "        if load_weight_path is not None:\n",
    "            self.model = self.load_weight()\n",
    "        \n",
    "        self\n",
    "        pass\n",
    "    \n",
    "    def build_model(self):\n",
    "        pass\n",
    "    \n",
    "    def load_model(self):\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, observation):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot1 = Bot()\n",
    "bot2 = Bot()\n",
    "\n",
    "player_list = [bot1, bot2]\n",
    "save_list = []\n",
    "\n",
    "for episode in range(100):\n",
    "    # reset environment\n",
    "    env.reset()\n",
    "    \n",
    "    # start from the 1st player\n",
    "    player_turn = 1\n",
    "    observation = env.observation\n",
    "    while game not end:\n",
    "        action = player_list[state['player_turn']].pick_action(observation)\n",
    "        \n",
    "        # if the action is not valid, the program will be break      \n",
    "        state, next_observation, reward = env.step(action)\n",
    "        \n",
    "        save_list.append([observation, action, next_observation, reward])\n",
    "        observation = next_observation\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.zeros([9, 3])\n",
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
