{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from py_files.board import Board\n",
    "from py_files.player import Q_player, Random_player, Human\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_config = {'player_type':'human', 'hidden_layers_size':[20,10,30]}\n",
    "p2_config = {'player_type':'human', 'hidden_layers_size':[20,10,10]}\n",
    "\n",
    "win_reward = 1\n",
    "lose_reward = -1\n",
    "draw_reward = 0\n",
    "\n",
    "test_board = Board(p1_config=p1_config, p2_config=p2_config, \n",
    "                   win_reward=win_reward, lose_reward=lose_reward, \n",
    "                   draw_reward=draw_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: 0\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "1\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "4\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "0\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "2\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "6\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "3\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "5\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "7\n",
      "Pick a cell (top left is 0 and bottom right is 8): \n",
      "8\n"
     ]
    }
   ],
   "source": [
    "episode = 1\n",
    "\n",
    "test_board.train(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = test_board.get_player(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[array([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "        1,\n",
       "        0,\n",
       "        array([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
       "        False],\n",
       "       [array([-0., -1., -0., -0., -0., -0., -0., -0., -0.]),\n",
       "        4,\n",
       "        0,\n",
       "        array([-1., -1., -0., -0.,  1., -0., -0., -0., -0.]),\n",
       "        False],\n",
       "       [array([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
       "        0,\n",
       "        0,\n",
       "        array([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
       "        False],\n",
       "       [array([-1., -1., -0., -0.,  1., -0., -0., -0., -0.]),\n",
       "        2,\n",
       "        0,\n",
       "        array([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.]),\n",
       "        False],\n",
       "       [array([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
       "        6,\n",
       "        0,\n",
       "        array([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.]),\n",
       "        False],\n",
       "       [array([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.]),\n",
       "        3,\n",
       "        0,\n",
       "        array([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.]),\n",
       "        False],\n",
       "       [array([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.]),\n",
       "        5,\n",
       "        0,\n",
       "        array([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.]),\n",
       "        False],\n",
       "       [array([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.]),\n",
       "        7,\n",
       "        0,\n",
       "        array([-1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.]),\n",
       "        True],\n",
       "       [array([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.]),\n",
       "        8,\n",
       "        0,\n",
       "        array([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.]),\n",
       "        True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = p1.memory\n",
    "p1.memory.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.stack(memory.sample(2), axis=1)\n",
    "train\n",
    "\n",
    "np.stack(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': array([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       "  'action': 6,\n",
       "  'reward': 0,\n",
       "  'next_observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.])},\n",
       " {'observation': array([-0., -0.,  1., -0., -0., -0., -1., -0., -1.]),\n",
       "  'action': 0,\n",
       "  'reward': -1,\n",
       "  'next_observation': array([ 1., -0.,  1., -0., -0., -0., -1., -1., -1.])},\n",
       " {'observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.]),\n",
       "  'action': 7,\n",
       "  'reward': 1,\n",
       "  'next_observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  1.,  1.])},\n",
       " {'observation': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  'action': 8,\n",
       "  'reward': 0,\n",
       "  'next_observation': array([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.])}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.memory.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 8,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]},\n",
       " {'observation': [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0],\n",
       "  'action': 2,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [-0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -0.0, -1.0]},\n",
       " {'observation': [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       "  'action': 6,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]},\n",
       " {'observation': [-0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -0.0, -1.0],\n",
       "  'action': 0,\n",
       "  'reward': [-1, 1],\n",
       "  'next_observation': [1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -1.0, -1.0]},\n",
       " {'observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       "  'action': 7,\n",
       "  'reward': [1, -1],\n",
       "  'next_observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 2 6 0 7\n",
    "\n",
    "sample_ans = [{'observation': [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "               'action': 8,\n",
    "               'reward': 0,\n",
    "               'next_observation': [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
    "               'done': False\n",
    "              },\n",
    "              {'observation': [-0., -0., -0., -0., -0., -0., -0., -0., -1.],\n",
    "               'action': 2,\n",
    "               'reward': 0,\n",
    "               'next_observation': ([-0., -0.,  1., -0., -0., -0., -1., -0., -1.]),\n",
    "               'done': False\n",
    "              },\n",
    "              {'observation': ([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
    "               'action': 6,\n",
    "               'reward': 0,\n",
    "               'next_observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.]),\n",
    "               'done': False\n",
    "              },\n",
    "              {'observation': ([-0., -0.,  1., -0., -0., -0., -1., -0., -1.]),\n",
    "               'action': 0,\n",
    "               'reward': -1,\n",
    "               'next_observation': ([ 1., -0.,  1., -0., -0., -0., -1., -1., -1.]),\n",
    "               'done': True\n",
    "              },\n",
    "              {'observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.]),\n",
    "               'action': 7,\n",
    "               'reward': 1,\n",
    "               'next_observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  1.,  1.]),\n",
    "               'done': True\n",
    "              }]\n",
    "\n",
    "sample_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 1,\n",
       "  'reward': 0,\n",
       "  'next_observation': [0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " {'observation': [-0.0, -1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0],\n",
       "  'action': 4,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0]},\n",
       " {'observation': [0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 0,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0],\n",
       "  'action': 2,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, -0.0, 1.0, -0.0, -1.0, -0.0, -0.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 6,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, 1.0, -0.0, 1.0, -0.0, -1.0, -0.0, -0.0],\n",
       "  'action': 3,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.0, -0.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0],\n",
       "  'action': 5,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.0, -0.0],\n",
       "  'action': 7,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0],\n",
       "  'action': 8,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 4 0 2 6 3 5 7 8\n",
    "\n",
    "sample = [{'observation': ([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "           'action': 1,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.])},\n",
    "          {'observation': ([-0., -1., -0., -0., -0., -0., -0., -0., -0.]),\n",
    "           'action': 4,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1., -0., -0.,  1., -0., -0., -0., -0.])},\n",
    "          {'observation': ([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
    "           'action': 0,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.])},\n",
    "          {'observation': ([-1., -1., -0., -0.,  1., -0., -0., -0., -0.]),\n",
    "           'action': 2,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.])},\n",
    "          {'observation': ([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
    "           'action': 6,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.])},\n",
    "          {'observation': ([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.]),\n",
    "           'action': 3,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.])},\n",
    "          {'observation': ([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.]),\n",
    "           'action': 5,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.])},\n",
    "          {'observation': ([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.]),\n",
    "           'action': 7,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.])},\n",
    "          {'observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.]),\n",
    "           'action': 8,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.])}]\n",
    "\n",
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
