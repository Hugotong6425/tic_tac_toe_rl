{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_files.board import Board\n",
    "from py_files.player import Q_player, Random_player, Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_config = {'player_type':'random', 'hidden_layers_size':[20,10,30]}\n",
    "p2_config = {'player_type':'random', 'hidden_layers_size':[20,10,10]}\n",
    "\n",
    "win_reward = 1\n",
    "lose_reward = -1\n",
    "draw_reward = 0\n",
    "\n",
    "test_board = Board(p1_config=p1_config, p2_config=p2_config, \n",
    "                   win_reward=win_reward, lose_reward=lose_reward, \n",
    "                   draw_reward=draw_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: 0\n",
      "Current episode: 1000\n",
      "Current episode: 2000\n",
      "Current episode: 3000\n",
      "Current episode: 4000\n"
     ]
    }
   ],
   "source": [
    "episode = 5000\n",
    "\n",
    "test_board.train(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = test_board.get_player(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([{'observation': array([-0., -0., -0., -0., -0., -0., -0., -0., -0.]),\n",
       "        'action': 8,\n",
       "        'reward': 0,\n",
       "        'next_observation': array([-0., -0., -1., -0., -0., -0., -0., -0.,  1.])},\n",
       "       {'observation': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.]),\n",
       "        'action': 2,\n",
       "        'reward': 0,\n",
       "        'next_observation': array([ 0.,  0.,  1.,  0.,  0.,  0., -1.,  0., -1.])},\n",
       "       {'observation': array([-0., -0., -1., -0., -0., -0., -0., -0.,  1.]),\n",
       "        'action': 6,\n",
       "        'reward': 0,\n",
       "        'next_observation': array([-1., -0., -1., -0., -0., -0.,  1., -0.,  1.])},\n",
       "       {'observation': array([ 0.,  0.,  1.,  0.,  0.,  0., -1.,  0., -1.]),\n",
       "        'action': 0,\n",
       "        'reward': -1,\n",
       "        'next_observation': array([ 1.,  0.,  1.,  0.,  0.,  0., -1., -1., -1.])},\n",
       "       {'observation': array([-1., -0., -1., -0., -0., -0.,  1., -0.,  1.]),\n",
       "        'action': 7,\n",
       "        'reward': 1,\n",
       "        'next_observation': array([-1., -0., -1., -0., -0., -0.,  1.,  1.,  1.])}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.memory.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': array([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       "  'action': 6,\n",
       "  'reward': 0,\n",
       "  'next_observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.])},\n",
       " {'observation': array([-0., -0.,  1., -0., -0., -0., -1., -0., -1.]),\n",
       "  'action': 0,\n",
       "  'reward': -1,\n",
       "  'next_observation': array([ 1., -0.,  1., -0., -0., -0., -1., -1., -1.])},\n",
       " {'observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.]),\n",
       "  'action': 7,\n",
       "  'reward': 1,\n",
       "  'next_observation': array([-1.,  0., -1.,  0.,  0.,  0.,  1.,  1.,  1.])},\n",
       " {'observation': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  'action': 8,\n",
       "  'reward': 0,\n",
       "  'next_observation': array([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.])}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.memory.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 8,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]},\n",
       " {'observation': [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0],\n",
       "  'action': 2,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [-0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -0.0, -1.0]},\n",
       " {'observation': [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       "  'action': 6,\n",
       "  'reward': [0, 0],\n",
       "  'next_observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]},\n",
       " {'observation': [-0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -0.0, -1.0],\n",
       "  'action': 0,\n",
       "  'reward': [-1, 1],\n",
       "  'next_observation': [1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -1.0, -1.0, -1.0]},\n",
       " {'observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
       "  'action': 7,\n",
       "  'reward': [1, -1],\n",
       "  'next_observation': [-1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 2 6 0 7\n",
    "\n",
    "sample_ans = [{'observation': [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "               'action': 8,\n",
    "               'reward': 0,\n",
    "               'next_observation': [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.]},\n",
    "              {'observation': [-0., -0., -0., -0., -0., -0., -0., -0., -1.],\n",
    "               'action': 2,\n",
    "               'reward': 0,\n",
    "               'next_observation': ([-0., -0.,  1., -0., -0., -0., -1., -0., -1.])},\n",
    "              {'observation': ([ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
    "               'action': 6,\n",
    "               'reward': 0,\n",
    "               'next_observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.])},\n",
    "              {'observation': ([-0., -0.,  1., -0., -0., -0., -1., -0., -1.]),\n",
    "               'action': 0,\n",
    "               'reward': -1,\n",
    "               'next_observation': ([ 1., -0.,  1., -0., -0., -0., -1., -1., -1.])},\n",
    "              {'observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  1.]),\n",
    "               'action': 7,\n",
    "               'reward': 1,\n",
    "               'next_observation': ([-1.,  0., -1.,  0.,  0.,  0.,  1.,  1.,  1.])}]\n",
    "\n",
    "sample_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'observation': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 1,\n",
       "  'reward': 0,\n",
       "  'next_observation': [0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " {'observation': [-0.0, -1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0],\n",
       "  'action': 4,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0]},\n",
       " {'observation': [0.0, 1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 0,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0],\n",
       "  'action': 2,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, -0.0, 1.0, -0.0, -1.0, -0.0, -0.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'action': 6,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, 1.0, -0.0, 1.0, -0.0, -1.0, -0.0, -0.0],\n",
       "  'action': 3,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.0, -0.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, -1.0, -1.0, 0.0, 1.0, 0.0, 0.0],\n",
       "  'action': 5,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0]},\n",
       " {'observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.0, -0.0],\n",
       "  'action': 7,\n",
       "  'reward': 0,\n",
       "  'next_observation': [-1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0]},\n",
       " {'observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 0.0],\n",
       "  'action': 8,\n",
       "  'reward': 0,\n",
       "  'next_observation': [1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 4 0 2 6 3 5 7 8\n",
    "\n",
    "sample = [{'observation': ([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "           'action': 1,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.])},\n",
    "          {'observation': ([-0., -1., -0., -0., -0., -0., -0., -0., -0.]),\n",
    "           'action': 4,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1., -0., -0.,  1., -0., -0., -0., -0.])},\n",
    "          {'observation': ([ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
    "           'action': 0,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.])},\n",
    "          {'observation': ([-1., -1., -0., -0.,  1., -0., -0., -0., -0.]),\n",
    "           'action': 2,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.])},\n",
    "          {'observation': ([ 1.,  1., -1.,  0., -1.,  0.,  0.,  0.,  0.]),\n",
    "           'action': 6,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.])},\n",
    "          {'observation': ([-1., -1.,  1., -0.,  1., -0., -1., -0., -0.]),\n",
    "           'action': 3,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.])},\n",
    "          {'observation': ([ 1.,  1., -1., -1., -1.,  0.,  1.,  0.,  0.]),\n",
    "           'action': 5,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.])},\n",
    "          {'observation': ([-1., -1.,  1.,  1.,  1., -1., -1., -0., -0.]),\n",
    "           'action': 7,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([-1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.])},\n",
    "          {'observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  0.]),\n",
    "           'action': 8,\n",
    "           'reward': 0,\n",
    "           'next_observation': ([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.])}]\n",
    "\n",
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
